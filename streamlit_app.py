# streamlit_app.py - ê¸°ê³„ ì†Œë¦¬ ì§„ë‹¨ ì›¹ UI (ìˆ˜ì •ëœ ë²„ì „)
import streamlit as st
import librosa
import soundfile as sf
import numpy as np
import matplotlib.pyplot as plt
import io
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime
import time

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ğŸ”§ ê¸°ê³„ ì†Œë¦¬ ì§„ë‹¨ ì‹œìŠ¤í…œ",
    page_icon="ğŸ”§",
    layout="wide"
)

# ì„¤ì • ë³€ìˆ˜
THRESH_DB = -35
COSINE_THRESH = 0.8
COSINE_THRESH_LOW = 0.6

@st.cache_data
def calculate_rms_dbfs(audio):
    """RMS(dBFS) ê³„ì‚°"""
    rms = np.sqrt(np.mean(audio**2))
    if rms == 0:
        return -np.inf
    return 20 * np.log10(rms)

@st.cache_data
def extract_features(audio, sr):
    """ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ"""
    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=32)
    mel_features = np.mean(mel_spec, axis=1)
    
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=8)
    mfcc_features = np.mean(mfcc, axis=1)
    
    spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)
    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)
    zero_crossing_rate = librosa.feature.zero_crossing_rate(audio)
    
    features = np.concatenate([
        mel_features,
        mfcc_features,
        [np.mean(spectral_centroids)],
        [np.mean(spectral_rolloff)],
        [np.mean(zero_crossing_rate)]
    ])
    
    return features

def load_baseline_features(baseline_files):
    """ë² ì´ìŠ¤ë¼ì¸ íŠ¹ì§• ë¡œë“œ"""
    if not baseline_files:
        return None, 0
    
    start_time = time.time()
    all_features = []
    
    for uploaded_file in baseline_files:
        try:
            audio_data = uploaded_file.getvalue()
            audio, sr = librosa.load(io.BytesIO(audio_data), sr=16000, mono=True)
            features = extract_features(audio, sr)
            all_features.append(features)
        except Exception as e:
            st.error(f"ë² ì´ìŠ¤ë¼ì¸ íŒŒì¼ {uploaded_file.name} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    
    processing_time = (time.time() - start_time) * 1000
    
    if all_features:
        return np.mean(all_features, axis=0), processing_time
    return None, processing_time

def judge_status(rms, similarity=None, thresh_db=-35):
    """ìƒíƒœ íŒì •"""
    rms_ok = rms <= thresh_db
    
    if similarity is None:
        return "ì •ìƒ" if rms_ok else "ê³ ì¥"
    
    cos_ok = similarity >= COSINE_THRESH
    cos_mid = similarity >= COSINE_THRESH_LOW
    
    if rms_ok and cos_ok:
        return "ì •ìƒ"
    elif rms_ok and cos_mid:
        return "ì¬ì¸¡ì •"
    elif cos_ok and not rms_ok:
        return "ì¬ì¸¡ì •"
    else:
        return "ê³ ì¥"

def create_gauge_chart(rms, similarity=None, status="ì •ìƒ", thresh_db=-35):
    """ê²Œì´ì§€ ì°¨íŠ¸ ìƒì„±"""
    if similarity is not None:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))
    else:
        fig, ax1 = plt.subplots(1, 1, figsize=(5, 4))
    
    # RMS ê²Œì´ì§€
    rms_normalized = max(0, min(100, (rms + 60) / 60 * 100))
    
    colors = {"ì •ìƒ": "green", "ì¬ì¸¡ì •": "orange", "ê³ ì¥": "red"}
    color = colors.get(status, "gray")
    
    bars1 = ax1.barh(['RMS Level'], [rms_normalized], color=color, height=0.3)
    
    thresh_normalized = max(0, min(100, (thresh_db + 60) / 60 * 100))
    ax1.axvline(x=thresh_normalized, color='red', linestyle='--', linewidth=2, 
               label=f'ì„ê³„ì¹˜ ({thresh_db} dBFS)')
    
    ax1.set_xlim(0, 100)
    ax1.set_xlabel('RMS Level (%)')
    ax1.set_title(f'RMS: {rms:.1f} dBFS')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    if rms_normalized < 90:
        ax1.text(rms_normalized + 2, 0, f'{rms:.1f}', va='center', fontweight='bold')
    
    # ìœ ì‚¬ë„ ê²Œì´ì§€
    if similarity is not None:
        similarity_percent = similarity * 100
        
        if similarity >= COSINE_THRESH:
            color2 = 'green'
        elif similarity >= COSINE_THRESH_LOW:
            color2 = 'orange'
        else:
            color2 = 'red'
        
        bars2 = ax2.barh(['Similarity'], [similarity_percent], color=color2, height=0.3)
        
        ax2.axvline(x=COSINE_THRESH * 100, color='green', linestyle='--', linewidth=2)
        ax2.axvline(x=COSINE_THRESH_LOW * 100, color='orange', linestyle='--', linewidth=2)
        
        ax2.set_xlim(0, 100)
        ax2.set_xlabel('Similarity (%)')
        ax2.set_title(f'Similarity: {similarity:.3f}')
        ax2.grid(True, alpha=0.3)
        
        if similarity_percent < 90:
            ax2.text(similarity_percent + 2, 0, f'{similarity:.3f}', va='center', fontweight='bold')
    
    plt.tight_layout()
    return fig

def create_waveform_plot(audio, sr, status):
    """íŒŒí˜• í”Œë¡¯ ìƒì„±"""
    fig, ax = plt.subplots(1, 1, figsize=(10, 4))
    
    time = np.linspace(0, len(audio)/sr, len(audio))
    ax.plot(time, audio)
    ax.set_title(f"Waveform - {status}")
    ax.set_xlabel('Time (seconds)')
    ax.set_ylabel('Amplitude')
    ax.grid(True)
    
    plt.tight_layout()
    return fig

def analyze_audio_file(uploaded_file, baseline_features, thresh_db):
    """ì•ˆì „í•œ ì˜¤ë””ì˜¤ ë¶„ì„"""
    try:
        # íŒŒì¼ í¬ê¸° ì²´í¬
        if uploaded_file.size > 100 * 1024 * 1024:  # 100MB
            return None, f"íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ (ìµœëŒ€ 100MB, í˜„ì¬: {uploaded_file.size/1024/1024:.1f}MB)"
        
        # ì „ì²´ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
        total_start = time.time()
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio_data = uploaded_file.getvalue()
        load_start = time.time()
        audio, sr = librosa.load(io.BytesIO(audio_data), sr=16000, mono=True)
        load_time = (time.time() - load_start) * 1000
        
        if len(audio) == 0:
            return None, "ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
        
        # RMS ê³„ì‚°
        rms_start = time.time()
        rms = calculate_rms_dbfs(audio)
        rms_time = (time.time() - rms_start) * 1000
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        similarity = None
        similarity_time = 0
        
        if baseline_features is not None:
            sim_start = time.time()
            try:
                features = extract_features(audio, sr)
                similarity = cosine_similarity([baseline_features], [features])[0][0]
                similarity_time = (time.time() - sim_start) * 1000
            except:
                similarity = None
        
        # ìƒíƒœ íŒì •
        status = judge_status(rms, similarity, thresh_db)
        
        total_time = (time.time() - total_start) * 1000
        
        return {
            'audio': audio,
            'sr': sr,
            'rms': rms,
            'similarity': similarity,
            'status': status,
            'load_time': load_time,
            'rms_time': rms_time,
            'similarity_time': similarity_time,
            'total_time': total_time
        }, None
        
    except Exception as e:
        return None, f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"

# ë©”ì¸ UI
def main():
    st.title("ğŸ”§ ê¸°ê³„ ì†Œë¦¬ ì§„ë‹¨ ì‹œìŠ¤í…œ")
    st.markdown("ì••ì¶•ê¸°, ëª¨í„°, ë² ì–´ë§ ë“±ì˜ ê¸°ê³„ ì†Œë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ìƒíƒœë¥¼ ì§„ë‹¨í•©ë‹ˆë‹¤.")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.header("âš™ï¸ ì„¤ì •")
    
    # ì„ê³„ì¹˜ ì¡°ì • ìŠ¬ë¼ì´ë”
    st.sidebar.subheader("ğŸšï¸ ì„ê³„ì¹˜ ì¡°ì •")
    thresh_db = st.sidebar.slider(
        "RMS ì„ê³„ì¹˜ (dBFS)",
        min_value=-60,
        max_value=-10,
        value=-35,
        step=1,
        help="ë‚®ì„ìˆ˜ë¡ ì—„ê²©í•œ ê¸°ì¤€"
    )
    
    st.sidebar.info(f"í˜„ì¬ ê¸°ì¤€: {thresh_db} dBFS")
    
    # ë² ì´ìŠ¤ë¼ì¸ íŒŒì¼ ì—…ë¡œë“œ
    st.sidebar.subheader("ğŸ“ ì •ìƒ ë² ì´ìŠ¤ë¼ì¸ íŒŒì¼")
    baseline_files = st.sidebar.file_uploader(
        "ì •ìƒ ìƒíƒœ WAV íŒŒì¼ë“¤ (3ê°œ ê¶Œì¥)",
        type=['wav'],
        accept_multiple_files=True,
        key="baseline"
    )
    
    # ë² ì´ìŠ¤ë¼ì¸ ì²˜ë¦¬
    baseline_features = None
    baseline_time = 0
    if baseline_files:
        with st.sidebar:
            with st.spinner("ë² ì´ìŠ¤ë¼ì¸ ë¡œë”© ì¤‘..."):
                baseline_features, baseline_time = load_baseline_features(baseline_files)
            if baseline_features is not None:
                st.success(f"âœ… {len(baseline_files)}ê°œ ë² ì´ìŠ¤ë¼ì¸ ë¡œë“œë¨")
                st.info(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {baseline_time:.1f}ms")
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸµ ë¶„ì„í•  WAV íŒŒì¼ ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "WAV íŒŒì¼ì„ ë“œë˜ê·¸ ì•¤ ë“œë¡­í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['wav'],
            key="test_file"
        )
        
        if uploaded_file is not None:
            st.info(f"ğŸ“ íŒŒì¼ëª…: {uploaded_file.name}")
            st.info(f"ğŸ“Š íŒŒì¼ í¬ê¸°: {uploaded_file.size / 1024:.1f} KB")
            
            with st.spinner("ë¶„ì„ ì¤‘..."):
                result, error = analyze_audio_file(uploaded_file, baseline_features, thresh_db)
            
            if error:
                st.error(f"âŒ ì˜¤ë¥˜: {error}")
                st.markdown("""
                ### ğŸ› ï¸ ë¬¸ì œ í•´ê²°:
                - WAV íŒŒì¼ë§Œ ì§€ì›ë©ë‹ˆë‹¤
                - ìµœëŒ€ íŒŒì¼ í¬ê¸°: 100MB
                - ìµœì†Œ ê¸¸ì´: 0.1ì´ˆ ì´ìƒ
                """)
            else:
                # ë¶„ì„ ì„±ê³µ
                audio = result['audio']
                sr = result['sr']
                rms = result['rms']
                similarity = result['similarity']
                status = result['status']
                
                # ê²°ê³¼ í‘œì‹œ
                st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
                
                if status == "ì •ìƒ":
                    st.success(f"ğŸŸ¢ **íŒì •: {status}**")
                elif status == "ì¬ì¸¡ì •":
                    st.warning(f"ğŸŸ¡ **íŒì •: {status}**")
                else:
                    st.error(f"ğŸ”´ **íŒì •: {status}**")
                
                # ìƒì„¸ ì •ë³´
                col_info1, col_info2, col_info3 = st.columns(3)
                
                with col_info1:
                    st.metric("RMS (dBFS)", f"{rms:.2f}")
                    st.metric("ê¸¸ì´ (ì´ˆ)", f"{len(audio)/sr:.2f}")
                
                with col_info2:
                    if similarity is not None:
                        st.metric("ìœ ì‚¬ë„", f"{similarity:.3f}")
                    st.metric("ìƒ˜í”Œë§ ë ˆì´íŠ¸", f"{sr} Hz")
                
                with col_info3:
                    st.metric("ì²˜ë¦¬ ì‹œê°„", f"{result['total_time']:.1f} ms")
                    st.metric("í˜„ì¬ ì„ê³„ì¹˜", f"{thresh_db} dBFS")
                
                # ê²Œì´ì§€ ì°¨íŠ¸
                st.subheader("ğŸ“ˆ ê²Œì´ì§€ ì°¨íŠ¸")
                gauge_fig = create_gauge_chart(rms, similarity, status, thresh_db)
                st.pyplot(gauge_fig)
                
                # íŒŒí˜• ì°¨íŠ¸
                st.subheader("ğŸŒŠ íŒŒí˜• ë¶„ì„")
                waveform_fig = create_waveform_plot(audio, sr, status)
                st.pyplot(waveform_fig)
    
    with col2:
        st.subheader("ğŸ“‹ ì§„ë‹¨ ê¸°ì¤€")
        
        st.markdown(f"""
        **RMS ì„ê³„ì¹˜:** {thresh_db} dBFS
        
        **íŒì • ê¸°ì¤€:**
        - ğŸŸ¢ **ì •ìƒ**: RMS â‰¤ {thresh_db} dBFS
        - ğŸŸ¡ **ì¬ì¸¡ì •**: ì• ë§¤í•œ ê²½ê³„ê°’
        - ğŸ”´ **ê³ ì¥**: RMS > {thresh_db} dBFS
        
        **ìœ ì‚¬ë„ ê¸°ì¤€** (ë² ì´ìŠ¤ë¼ì¸ ì‚¬ìš©ì‹œ):
        - ğŸŸ¢ **ì •ìƒ**: â‰¥ {COSINE_THRESH}
        - ğŸŸ¡ **ì¬ì¸¡ì •**: {COSINE_THRESH_LOW} ~ {COSINE_THRESH}
        - ğŸ”´ **ê³ ì¥**: < {COSINE_THRESH_LOW}
        """)
        
        if baseline_features is not None:
            st.success("âœ… ë² ì´ìŠ¤ë¼ì¸ í™œì„±í™”ë¨")
        else:
            st.warning("âš ï¸ ë² ì´ìŠ¤ë¼ì¸ ì—†ìŒ")

if __name__ == "__main__":
    main()